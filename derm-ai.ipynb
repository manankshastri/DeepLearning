{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator as idg\n",
    "train_data = idg(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "valid_data = idg(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_data = idg(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = train_data.flow_from_directory('E:\\\\data\\\\train', target_size=(32, 32), batch_size=32, class_mode='categorical')\n",
    "validation_data = valid_data.flow_from_directory('E:\\\\data\\\\valid', target_size=(32, 32), batch_size=32, class_mode='categorical')\n",
    "test_data = test_data.flow_from_directory('E:\\\\data\\\\test', target_size=(32, 32), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               1024500   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 1,067,571\n",
      "Trainable params: 1,067,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 613s 20s/step - loss: 0.7761 - acc: 0.6979 - val_loss: 1.1335 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.13349, saving model to derm-best-model\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 477s 16s/step - loss: 0.7849 - acc: 0.6792 - val_loss: 1.2062 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.13349\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 472s 16s/step - loss: 0.7860 - acc: 0.6719 - val_loss: 0.8712 - val_acc: 0.5378\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.13349 to 0.87120, saving model to derm-best-model\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 418s 14s/step - loss: 0.7597 - acc: 0.6906 - val_loss: 0.9249 - val_acc: 0.5356\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.87120\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 439s 15s/step - loss: 0.7329 - acc: 0.7198 - val_loss: 0.9412 - val_acc: 0.5244\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.87120\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 399s 13s/step - loss: 0.7439 - acc: 0.6906 - val_loss: 0.9333 - val_acc: 0.5422\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.87120\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 434s 14s/step - loss: 0.7661 - acc: 0.6740 - val_loss: 0.8241 - val_acc: 0.5744\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.87120 to 0.82408, saving model to derm-best-model\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 538s 18s/step - loss: 0.7378 - acc: 0.6970 - val_loss: 0.8525 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.82408\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 440s 15s/step - loss: 0.7213 - acc: 0.7094 - val_loss: 0.9298 - val_acc: 0.5344\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.82408\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 405s 14s/step - loss: 0.7153 - acc: 0.6927 - val_loss: 0.8677 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.82408\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 400s 13s/step - loss: 0.6929 - acc: 0.7198 - val_loss: 0.8285 - val_acc: 0.5722\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.82408\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 408s 14s/step - loss: 0.7313 - acc: 0.6896 - val_loss: 0.8185 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.82408 to 0.81851, saving model to derm-best-model\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 403s 13s/step - loss: 0.7440 - acc: 0.6865 - val_loss: 0.8060 - val_acc: 0.5867\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.81851 to 0.80600, saving model to derm-best-model\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 409s 14s/step - loss: 0.6937 - acc: 0.7063 - val_loss: 0.8043 - val_acc: 0.5989\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.80600 to 0.80427, saving model to derm-best-model\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 395s 13s/step - loss: 0.7258 - acc: 0.6958 - val_loss: 0.8035 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.80427 to 0.80352, saving model to derm-best-model\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 427s 14s/step - loss: 0.6882 - acc: 0.7042 - val_loss: 0.7966 - val_acc: 0.6033\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.80352 to 0.79658, saving model to derm-best-model\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 396s 13s/step - loss: 0.7066 - acc: 0.7114 - val_loss: 0.9518 - val_acc: 0.5678\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.79658\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 414s 14s/step - loss: 0.6647 - acc: 0.7260 - val_loss: 0.8824 - val_acc: 0.5644\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.79658\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 399s 13s/step - loss: 0.7011 - acc: 0.6959 - val_loss: 0.8907 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.79658\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 407s 14s/step - loss: 0.6842 - acc: 0.7000 - val_loss: 0.7661 - val_acc: 0.6478\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.79658 to 0.76615, saving model to derm-best-model\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='derm-best-model', verbose=1, save_best_only=True)\n",
    "hist = model.fit_generator(training_data, steps_per_epoch=30, epochs=20, verbose=1, callbacks=[checkpointer], \n",
    "                           validation_data = (validation_data), validation_steps = 30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('derm-best-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.701666666667\n"
     ]
    }
   ],
   "source": [
    "# evaluate and print test accuracy\n",
    "score = model.evaluate_generator(test_data, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_data, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20775467  0.73647171  0.05577361]\n",
      " [ 0.27240661  0.45568585  0.27190751]\n",
      " [ 0.32488066  0.60155147  0.07356779]\n",
      " ..., \n",
      " [ 0.33580443  0.39660552  0.26758999]\n",
      " [ 0.23638368  0.64653587  0.11708048]\n",
      " [ 0.31824487  0.64059627  0.04115896]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
